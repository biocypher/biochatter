Access,Domain,Name,Format,Size (dev/test),Abstract,Year,Note,
https://github.com/jind11/MedQA,General medical knowledge in US medical licensing exam,MedQA (USMLE),Q + A (4-5 choices),11450/1273,https://www.mdpi.com/2076-3417/11/14/6421,2021,,
https://www.nature.com/articles/s41586-023-06291-2#Sec59,"Combines six existing medical question answering datasets (HealthSearchQA, MedMCQA (AIIMS/NEET), PubMedQA, MMLU, LiveQA TREC-2017, MedicationQA)",MultiMedQA,"Q + A, multiple choice, open domain",11450/173,https://www.nature.com/articles/s41586-023-06291-2#Sec59,2023,,
https://www.nature.com/articles/s41586-023-06291-2#Sec59,General medical knowledge searched for by consumers,HealthSearchQA,Q + Manual Expert Evaluation,3375,https://www.nature.com/articles/s41586-023-06291-2#Sec59,2023,,
https://medmcqa.github.io/,General medical knowledge in Indian medical entrance exams,MedMCQA (AIIMS/NEET),Q + A (4 choices and explanations),187000/6100,https://proceedings.mlr.press/v174/pal22a.html,2022,,
https://pubmedqa.github.io/,Biomedical scientific literature,PubMedQA,Q + Context + A (Yes/No/Maybe) (Long Answer),500/500 #QA pairs: Labeled: 1000; Unlabeled: 61200; Synthetic: 211300,https://arxiv.org/abs/1909.06146,2019,,
https://github.com/hendrycks/test,"Medical knowledge covering anatomy, clinical knowledge, college medicine, medical genetics, professional medicine, and college biology",MMLU,Q + A (4 choices),123/1089,https://arxiv.org/abs/2009.03300,2020,,
https://github.com/abachaa/LiveQA_MedicalTask_TREC2017,General medical knowledge sought by consumers,LiveQA TREC-2017,Q + Long Answer (Librarian Answers),634/104,https://trec.nist.gov/pubs/trec26/papers/Overview-QA.pdf?ref=https://githubhelp.com,2017,,
https://github.com/abachaa/Medication_QA_MedInfo2019,Medication knowledge frequently sought by consumers,MedicationQA,Q + A (Long Answer),NA/674,https://pubmed.ncbi.nlm.nih.gov/31437878/,2019,,
https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10470220/#appsec1,Opthamology related medical questions,"Benchmarking large language models’ performances for myopia care: a comparative analysis of ChatGPT-3.5, ChatGPT-4.0, and Google Bard",Q + A (Long Answer),31,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10470220/#appsec1,,,
https://bioconductor.org/packages/release/bioc/html/GSEABenchmarkeR.html,The GSEABenchmarkeR package implements an extendable framework for reproducible evaluation of set- and network-based methods for enrichment analysis of gene expression data,GSEABenchmarkeR,R package,,https://pubmed.ncbi.nlm.nih.gov/32026945/,,included in BioChatter Light arxiv draft-- not sure how helpful it will be in LLM benchmarking,
https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10153208/,cell type annotation with GPT-4 in single-cell RNA-seq analysis,Reference-free and cost-effective automated cell type annotation with GPT-4 in single-cell RNA-seq analysis,,,,2023,,
https://github.com/source-data/soda-data,text extraction from figure legends,SourceData,Unknown,Unknown,"Introduction: The scientific publishing landscape is expanding rapidly, creating challenges for researchers to stay up-to-date with the evolution of the literature. Natural Language Processing (NLP) has emerged as a potent approach to automating knowledge extraction from this vast amount of publications and preprints. Tasks such as Named-Entity Recognition (NER) and Named-Entity Linking (NEL), in conjunction with context-dependent semantic interpretation, offer promising and complementary approaches to extracting structured information and revealing key concepts. Results: We present the SourceData-NLP dataset produced through the routine curation of papers during the publication process. A unique feature of this dataset is its emphasis on the annotation of bioentities in figure legends. We annotate eight classes of biomedical entities (small molecules, gene products, subcellular components, cell lines, cell types, tissues, organisms, and diseases), their role in the experimental design, and the nature of the experimental method as an additional class. SourceData-NLP contains more than 620,000 annotated biomedical entities, curated from 18,689 figures in 3,223 papers in molecular and cell biology. We illustrate the dataset's usefulness by assessing BioLinkBERT and PubmedBERT, two transformers-based models, fine-tuned on the SourceData-NLP dataset for NER. We also introduce a novel context-dependent semantic task that infers whether an entity is the target of a controlled intervention or the object of measurement. Conclusions: SourceData-NLP's scale highlights the value of integrating curation into publishing. Models trained with SourceData-NLP will furthermore enable the development of tools able to extract causal hypotheses from the literature and assemble them into knowledge graphs.",2023,,
https://github.com/bigscience-workshop/biomedical,General Biomedical Dataset Library (126+ datasets included),BigBIO,Huggingface dataloaders (format depends on the dataset),,https://proceedings.neurips.cc/paper_files/paper/2022/file/a583d2197eafc4afdd41f5b8765555c5-Paper-Datasets_and_Benchmarks.pdf,2022,,
,,,,,,,,
