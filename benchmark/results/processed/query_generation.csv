Full model name,Score achieved,Score possible,Score SD,Accuracy,Iterations
gpt-3.5-turbo-0125,145.0,150.0,0,0.9666666666666667,5
gpt-4-0613,145.0,150.0,0,0.9666666666666667,5
code-llama-instruct:7:ggufv2:Q4_K_M,145.0,150.0,0,0.9666666666666667,5
code-llama-instruct:7:ggufv2:Q5_K_M,144.0,150.0,0,0.96,5
code-llama-instruct:7:ggufv2:Q8_0,144.0,150.0,0,0.96,5
code-llama-instruct:7:ggufv2:Q6_K,144.0,150.0,0,0.96,5
gpt-3.5-turbo-0613,142.0,150.0,0,0.9466666666666667,5
openhermes-2.5:7:ggufv2:Q3_K_M,141.0,150.0,0,0.94,5
openhermes-2.5:7:ggufv2:Q2_K,141.0,150.0,0,0.94,5
llama-3-instruct:8:ggufv2:Q6_K,139.0,150.0,0,0.9266666666666666,5
llama-3-instruct:8:ggufv2:Q5_K_M,139.0,150.0,0,0.9266666666666666,5
llama-3-instruct:8:ggufv2:Q4_K_M,138.0,150.0,0,0.92,5
llama-3-instruct:8:ggufv2:Q8_0,138.0,150.0,0,0.92,5
code-llama-instruct:7:ggufv2:Q2_K,138.0,150.0,0,0.92,5
llama-2-chat:70:ggufv2:Q4_K_M,138.0,150.0,0,0.92,5
openhermes-2.5:7:ggufv2:Q5_K_M,137.0,150.0,0,0.9133333333333333,5
llama-2-chat:70:ggufv2:Q3_K_M,136.0,150.0,0,0.9066666666666666,5
llama-2-chat:70:ggufv2:Q5_K_M,136.0,150.0,0,0.9066666666666666,5
code-llama-instruct:34:ggufv2:Q4_K_M,136.0,150.0,0,0.9066666666666666,5
code-llama-instruct:34:ggufv2:Q5_K_M,135.0,150.0,0,0.9,5
llama-2-chat:70:ggufv2:Q2_K,135.0,150.0,0,0.9,5
mixtral-instruct-v0.1:46_7:ggufv2:Q3_K_M,134.0,150.0,0,0.8933333333333333,5
openhermes-2.5:7:ggufv2:Q8_0,132.0,150.0,0,0.88,5
openhermes-2.5:7:ggufv2:Q4_K_M,131.0,150.0,0,0.8733333333333333,5
code-llama-instruct:7:ggufv2:Q3_K_M,131.0,150.0,0,0.8733333333333333,5
code-llama-instruct:34:ggufv2:Q8_0,129.0,150.0,0,0.86,5
openhermes-2.5:7:ggufv2:Q6_K,129.0,150.0,0,0.86,5
code-llama-instruct:34:ggufv2:Q6_K,128.0,150.0,0,0.8533333333333334,5
mistral-instruct-v0.2:7:ggufv2:Q8_0,127.0,150.0,0,0.8466666666666667,5
mixtral-instruct-v0.1:46_7:ggufv2:Q8_0,127.0,150.0,0,0.8466666666666667,5
mixtral-instruct-v0.1:46_7:ggufv2:Q5_K_M,126.0,150.0,0,0.84,5
gpt-4-0125-preview,125.0,150.0,0,0.8333333333333334,5
code-llama-instruct:13:ggufv2:Q4_K_M,125.0,150.0,0,0.8333333333333334,5
code-llama-instruct:13:ggufv2:Q3_K_M,125.0,150.0,0,0.8333333333333334,5
mistral-instruct-v0.2:7:ggufv2:Q6_K,125.0,150.0,0,0.8333333333333334,5
mixtral-instruct-v0.1:46_7:ggufv2:Q6_K,124.0,150.0,0,0.8266666666666667,5
mistral-instruct-v0.2:7:ggufv2:Q5_K_M,124.0,150.0,0,0.8266666666666667,5
mistral-instruct-v0.2:7:ggufv2:Q4_K_M,124.0,150.0,0,0.8266666666666667,5
code-llama-instruct:13:ggufv2:Q2_K,123.0,150.0,0,0.82,5
llama-2-chat:13:ggufv2:Q6_K,122.0,150.0,0,0.8133333333333334,5
gpt-4o-2024-05-13,120.0,150.0,0,0.8,5
code-llama-instruct:13:ggufv2:Q6_K,119.0,150.0,0,0.7933333333333333,5
llama-2-chat:13:ggufv2:Q8_0,118.0,150.0,0,0.7866666666666666,5
code-llama-instruct:34:ggufv2:Q3_K_M,118.0,150.0,0,0.7866666666666666,5
code-llama-instruct:13:ggufv2:Q5_K_M,117.0,150.0,0,0.78,5
mistral-instruct-v0.2:7:ggufv2:Q3_K_M,116.0,150.0,0,0.7733333333333333,5
code-llama-instruct:13:ggufv2:Q8_0,115.0,150.0,0,0.7666666666666667,5
llama-2-chat:13:ggufv2:Q4_K_M,114.0,150.0,0,0.76,5
mixtral-instruct-v0.1:46_7:ggufv2:Q4_K_M,114.0,150.0,0,0.76,5
llama-2-chat:13:ggufv2:Q5_K_M,112.0,150.0,0,0.7466666666666667,5
mixtral-instruct-v0.1:46_7:ggufv2:Q2_K,109.0,150.0,0,0.7266666666666667,5
mistral-instruct-v0.2:7:ggufv2:Q2_K,104.0,150.0,0,0.6933333333333334,5
llama-2-chat:7:ggufv2:Q3_K_M,104.0,150.0,0,0.6933333333333334,5
code-llama-instruct:34:ggufv2:Q2_K,103.0,150.0,0,0.6866666666666666,5
llama-2-chat:7:ggufv2:Q2_K,103.0,150.0,0,0.6866666666666666,5
llama-2-chat:13:ggufv2:Q3_K_M,102.0,150.0,0,0.68,5
llama-2-chat:7:ggufv2:Q6_K,99.0,150.0,0,0.66,5
llama-2-chat:7:ggufv2:Q4_K_M,97.0,150.0,0,0.6466666666666666,5
llama-2-chat:7:ggufv2:Q8_0,96.0,150.0,0,0.64,5
llama-2-chat:7:ggufv2:Q5_K_M,95.0,150.0,0,0.6333333333333333,5
chatglm3:6:ggmlv3:q4_0,83.0,150.0,0,0.5533333333333333,5
llama-2-chat:13:ggufv2:Q2_K,65.0,150.0,0,0.43333333333333335,5
