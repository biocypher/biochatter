Full model name,Score achieved,Score possible,Score SD,Accuracy,Iterations
openhermes-2.5:7:ggufv2:Q8_0,60.0,60.0,0.0,1.0,5
gpt-3.5-turbo-0125,60.0,60.0,0.0,1.0,5
openhermes-2.5:7:ggufv2:Q6_K,60.0,60.0,0.0,1.0,5
openhermes-2.5:7:ggufv2:Q5_K_M,60.0,60.0,0.0,1.0,5
openhermes-2.5:7:ggufv2:Q4_K_M,60.0,60.0,0.0,1.0,5
openhermes-2.5:7:ggufv2:Q3_K_M,60.0,60.0,0.0,1.0,5
gpt-4-0125-preview,45.0,60.0,0.0,0.75,5
gpt-4-0613,39.0,60.0,0.0,0.65,5
openhermes-2.5:7:ggufv2:Q2_K,30.0,60.0,0.0,0.5,5
code-llama-instruct:34:ggufv2:Q2_K,30.0,60.0,0.0,0.5,5
gpt-3.5-turbo-0613,30.0,60.0,0.0,0.5,5
chatglm3:6:ggmlv3:q4_0,24.0,60.0,0.0,0.4,5
mixtral-instruct-v0.1:46_7:ggufv2:Q8_0,15.0,60.0,0.0,0.25,5
code-llama-instruct:7:ggufv2:Q3_K_M,15.0,60.0,0.0,0.25,5
code-llama-instruct:7:ggufv2:Q2_K,15.0,60.0,0.0,0.25,5
llama-2-chat:70:ggufv2:Q5_K_M,15.0,60.0,0.0,0.25,5
llama-2-chat:70:ggufv2:Q4_K_M,15.0,60.0,0.0,0.25,5
mixtral-instruct-v0.1:46_7:ggufv2:Q3_K_M,15.0,60.0,0.0,0.25,5
mixtral-instruct-v0.1:46_7:ggufv2:Q6_K,15.0,60.0,0.0,0.25,5
code-llama-instruct:34:ggufv2:Q3_K_M,15.0,60.0,0.0,0.25,5
mixtral-instruct-v0.1:46_7:ggufv2:Q5_K_M,15.0,60.0,0.0,0.25,5
llama-3-instruct:8:ggufv2:Q8_0,0.0,60.0,0.0,0.0,5
mistral-instruct-v0.2:7:ggufv2:Q3_K_M,0.0,60.0,0.0,0.0,5
mistral-instruct-v0.2:7:ggufv2:Q2_K,0.0,60.0,0.0,0.0,5
code-llama-instruct:34:ggufv2:Q8_0,0.0,60.0,0.0,0.0,5
mistral-instruct-v0.2:7:ggufv2:Q5_K_M,0.0,60.0,0.0,0.0,5
llama-3-instruct:8:ggufv2:Q6_K,0.0,60.0,0.0,0.0,5
llama-3-instruct:8:ggufv2:Q5_K_M,0.0,60.0,0.0,0.0,5
mistral-instruct-v0.2:7:ggufv2:Q4_K_M,0.0,60.0,0.0,0.0,5
mixtral-instruct-v0.1:46_7:ggufv2:Q2_K,0.0,60.0,0.0,0.0,5
mistral-instruct-v0.2:7:ggufv2:Q6_K,0.0,60.0,0.0,0.0,5
mistral-instruct-v0.2:7:ggufv2:Q8_0,0.0,60.0,0.0,0.0,5
llama-2-chat:7:ggufv2:Q8_0,0.0,60.0,0.0,0.0,5
mixtral-instruct-v0.1:46_7:ggufv2:Q4_K_M,0.0,60.0,0.0,0.0,5
code-llama-instruct:13:ggufv2:Q8_0,0.0,60.0,0.0,0.0,5
code-llama-instruct:13:ggufv2:Q6_K,0.0,60.0,0.0,0.0,5
code-llama-instruct:13:ggufv2:Q5_K_M,0.0,60.0,0.0,0.0,5
code-llama-instruct:13:ggufv2:Q4_K_M,0.0,60.0,0.0,0.0,5
code-llama-instruct:13:ggufv2:Q3_K_M,0.0,60.0,0.0,0.0,5
llama-3-instruct:8:ggufv2:Q4_K_M,0.0,60.0,0.0,0.0,5
llama-2-chat:7:ggufv2:Q4_K_M,0.0,60.0,0.0,0.0,5
llama-2-chat:7:ggufv2:Q6_K,0.0,60.0,0.0,0.0,5
gpt-4o-mini-2024-07-18,0.0,60.0,0.0,0.0,5
code-llama-instruct:7:ggufv2:Q4_K_M,0.0,60.0,0.0,0.0,5
code-llama-instruct:7:ggufv2:Q5_K_M,0.0,60.0,0.0,0.0,5
code-llama-instruct:7:ggufv2:Q6_K,0.0,60.0,0.0,0.0,5
code-llama-instruct:7:ggufv2:Q8_0,0.0,60.0,0.0,0.0,5
code-llama-instruct:34:ggufv2:Q6_K,0.0,60.0,0.0,0.0,5
code-llama-instruct:34:ggufv2:Q5_K_M,0.0,60.0,0.0,0.0,5
code-llama-instruct:34:ggufv2:Q4_K_M,0.0,60.0,0.0,0.0,5
gpt-4-turbo-2024-04-09,0.0,60.0,0.0,0.0,5
gpt-4o-2024-05-13,0.0,60.0,0.0,0.0,5
llama-2-chat:13:ggufv2:Q2_K,0.0,60.0,0.0,0.0,5
llama-2-chat:7:ggufv2:Q5_K_M,0.0,60.0,0.0,0.0,5
llama-2-chat:13:ggufv2:Q3_K_M,0.0,60.0,0.0,0.0,5
llama-2-chat:13:ggufv2:Q4_K_M,0.0,60.0,0.0,0.0,5
llama-2-chat:13:ggufv2:Q5_K_M,0.0,60.0,0.0,0.0,5
llama-2-chat:13:ggufv2:Q6_K,0.0,60.0,0.0,0.0,5
llama-2-chat:13:ggufv2:Q8_0,0.0,60.0,0.0,0.0,5
code-llama-instruct:13:ggufv2:Q2_K,0.0,60.0,0.0,0.0,5
llama-2-chat:70:ggufv2:Q3_K_M,0.0,60.0,0.0,0.0,5
llama-2-chat:7:ggufv2:Q2_K,0.0,60.0,0.0,0.0,5
llama-2-chat:7:ggufv2:Q3_K_M,0.0,60.0,0.0,0.0,5
llama-2-chat:70:ggufv2:Q2_K,0.0,60.0,0.0,0.0,5
