Full model name,Score achieved,Score possible,Score SD,Accuracy,Iterations
claude-3-opus-20240229,24.0,24.0,0.0,1.0,3
code-llama-instruct:34:ggufv2:Q4_K_M,39.0,40.0,0.0,0.975,5
code-llama-instruct:34:ggufv2:Q5_K_M,38.0,40.0,0.0,0.95,5
code-llama-instruct:34:ggufv2:Q8_0,37.0,40.0,0.0,0.925,5
llama-3.1-instruct:70:ggufv2:IQ2_M,22.0,24.0,0.5773502691896257,0.9166666666666666,3
code-llama-instruct:34:ggufv2:Q6_K,36.0,40.0,0.0,0.9,5
code-llama-instruct:13:ggufv2:Q2_K,35.0,40.0,0.0,0.875,5
code-llama-instruct:34:ggufv2:Q3_K_M,35.0,40.0,0.0,0.875,5
claude-3-5-sonnet-20240620,26.0,30.0,0.5773502691896258,0.8666666666666667,3
code-llama-instruct:13:ggufv2:Q3_K_M,34.0,40.0,0.0,0.85,5
mixtral-instruct-v0.1:46_7:ggufv2:Q6_K,34.0,40.0,0.0,0.85,5
llama-3.1-instruct:8:ggufv2:Q6_K,20.0,24.0,1.1547005383792515,0.8333333333333334,3
llama-3.1-instruct:8:ggufv2:Q5_K_M,20.0,24.0,1.1547005383792515,0.8333333333333334,3
code-llama-instruct:13:ggufv2:Q6_K,33.0,40.0,0.0,0.825,5
code-llama-instruct:7:ggufv2:Q2_K,32.0,40.0,0.0,0.8,5
code-llama-instruct:7:ggufv2:Q3_K_M,36.0,45.0,0.0,0.8,5
gpt-3.5-turbo-0125,45.0,57.0,0.0,0.7894736842105263,5
llama-2-chat:13:ggufv2:Q4_K_M,35.0,45.0,0.0,0.7777777777777778,5
mixtral-instruct-v0.1:46_7:ggufv2:Q3_K_M,35.0,45.0,0.0,0.7777777777777778,5
llama-2-chat:70:ggufv2:Q5_K_M,35.0,45.0,0.0,0.7777777777777778,5
llama-2-chat:70:ggufv2:Q3_K_M,35.0,45.0,0.0,0.7777777777777778,5
code-llama-instruct:7:ggufv2:Q6_K,31.0,40.0,0.0,0.775,5
llama-3-instruct:8:ggufv2:Q6_K,31.0,40.0,0.0,0.775,5
llama-3-instruct:8:ggufv2:Q4_K_M,31.0,40.0,0.0,0.775,5
code-llama-instruct:13:ggufv2:Q5_K_M,31.0,40.0,0.0,0.775,5
code-llama-instruct:13:ggufv2:Q4_K_M,31.0,40.0,0.0,0.775,5
llama-2-chat:13:ggufv2:Q6_K,31.0,40.0,0.0,0.775,5
gpt-3.5-turbo-0613,34.0,45.0,0.0,0.7555555555555555,5
mixtral-instruct-v0.1:46_7:ggufv2:Q4_K_M,34.0,45.0,0.0,0.7555555555555555,5
llama-2-chat:70:ggufv2:Q4_K_M,34.0,45.0,0.0,0.7555555555555555,5
llama-3.1-instruct:70:ggufv2:IQ4_XS,18.0,24.0,0.0,0.75,3
code-llama-instruct:34:ggufv2:Q2_K,30.0,40.0,0.0,0.75,5
code-llama-instruct:13:ggufv2:Q8_0,30.0,40.0,0.0,0.75,5
mixtral-instruct-v0.1:46_7:ggufv2:Q2_K,33.0,45.0,0.0,0.7333333333333333,5
llama-2-chat:13:ggufv2:Q3_K_M,33.0,45.0,0.0,0.7333333333333333,5
llama-3-instruct:8:ggufv2:Q8_0,29.0,40.0,0.0,0.725,5
llama-2-chat:13:ggufv2:Q8_0,32.0,45.0,0.0,0.7111111111111111,5
mixtral-instruct-v0.1:46_7:ggufv2:Q5_K_M,32.0,45.0,0.0,0.7111111111111111,5
mistral-instruct-v0.2:7:ggufv2:Q5_K_M,31.0,45.0,0.0,0.6888888888888889,5
mistral-instruct-v0.2:7:ggufv2:Q4_K_M,31.0,45.0,0.0,0.6888888888888889,5
code-llama-instruct:7:ggufv2:Q5_K_M,31.0,45.0,0.0,0.6888888888888889,5
llama-2-chat:70:ggufv2:Q2_K,30.0,45.0,0.0,0.6666666666666666,5
code-llama-instruct:7:ggufv2:Q8_0,30.0,45.0,0.0,0.6666666666666666,5
gpt-4-0613,46.0,69.0,0.0,0.6666666666666666,5
mixtral-instruct-v0.1:46_7:ggufv2:Q8_0,30.0,45.0,0.0,0.6666666666666666,5
mistral-instruct-v0.2:7:ggufv2:Q3_K_M,30.0,45.0,0.0,0.6666666666666666,5
gpt-4-turbo-2024-04-09,46.0,70.0,0.0,0.6571428571428571,5
llama-3-instruct:8:ggufv2:Q5_K_M,26.0,40.0,0.0,0.65,5
mistral-instruct-v0.2:7:ggufv2:Q6_K,26.0,40.0,0.0,0.65,5
mistral-instruct-v0.2:7:ggufv2:Q8_0,29.0,45.0,0.0,0.6444444444444445,5
llama-2-chat:13:ggufv2:Q5_K_M,29.0,45.0,0.0,0.6444444444444445,5
llama-3.1-instruct:70:ggufv2:Q3_K_S,15.0,24.0,0.0,0.625,3
gpt-4-0125-preview,39.0,63.0,0.0,0.6190476190476191,5
code-llama-instruct:7:ggufv2:Q4_K_M,27.0,45.0,0.0,0.6,5
mistral-instruct-v0.2:7:ggufv2:Q2_K,27.0,45.0,0.0,0.6,5
gpt-4o-2024-05-13,40.0,76.0,0.0,0.5263157894736842,5
gpt-4o-mini-2024-07-18,43.0,82.0,0.5477225575051661,0.524390243902439,5
llama-3.1-instruct:8:ggufv2:IQ4_XS,29.0,66.0,0.0,0.4393939393939394,3
llama-2-chat:7:ggufv2:Q2_K,38.0,117.0,0.5773502691896258,0.3247863247863248,5
llama-2-chat:13:ggufv2:Q2_K,13.0,45.0,0.0,0.28888888888888886,5
chatglm3:6:ggmlv3:q4_0,11.0,40.0,0.0,0.275,5
llama-2-chat:7:ggufv2:Q4_K_M,34.0,135.0,1.1547005383792515,0.2518518518518518,5
llama-3.1-instruct:8:ggufv2:Q3_K_L,36.0,150.0,2.8867513459481287,0.24,3
llama-2-chat:7:ggufv2:Q3_K_M,28.0,135.0,1.1547005383792515,0.2074074074074074,5
openhermes-2.5:7:ggufv2:Q2_K,52.0,279.0,0.5773502691896258,0.1863799283154122,5
gpt-4o-2024-08-06,34.0,189.0,0.5773502691896257,0.17989417989417988,3
llama-2-chat:7:ggufv2:Q6_K,24.0,135.0,0.0,0.17777777777777778,5
llama-2-chat:7:ggufv2:Q8_0,25.0,153.0,1.0,0.16339869281045752,5
llama-3.1-instruct:8:ggufv2:Q8_0,33.0,204.0,1.7320508075688772,0.16176470588235295,3
openhermes-2.5:7:ggufv2:Q3_K_M,53.0,338.0,0.5773502691896258,0.15680473372781065,5
llama-2-chat:7:ggufv2:Q5_K_M,21.0,135.0,0.5773502691896257,0.15555555555555556,5
llama-3.1-instruct:8:ggufv2:Q4_K_M,28.0,186.0,0.5773502691896257,0.15053763440860216,3
openhermes-2.5:7:ggufv2:Q4_K_M,52.0,369.0,0.0,0.14092140921409213,5
openhermes-2.5:7:ggufv2:Q5_K_M,49.0,405.0,0.5773502691896258,0.12098765432098765,5
openhermes-2.5:7:ggufv2:Q6_K,50.0,441.0,0.5773502691896258,0.11337868480725624,5
openhermes-2.5:7:ggufv2:Q8_0,48.0,477.0,1.1547005383792515,0.10062893081761007,5
